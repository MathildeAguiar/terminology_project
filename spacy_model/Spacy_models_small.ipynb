{"cells":[{"cell_type":"markdown","metadata":{"id":"WwIPrtcWupfb"},"source":["# Terminology project \n","\n","## **Spacy trainable pipe**\n","\n","### AGUIAR Mathilde NIAOURI Dimitra\n","\n","#### M2 NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DLW1ZVblu5ZH"},"source":["# Goal and tools "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3947,"status":"ok","timestamp":1670068795654,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"PlYl49hV0NLR","outputId":"3361817d-ecb7-4b5f-eeb7-14fa49681358"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UWa0GcjdvK9E"},"source":["#### Imports and packages "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3335,"status":"ok","timestamp":1670274521625,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"nBDuuHj5Ip6Y","outputId":"339ef5cc-2121-41c1-82a9-5f5831e63d78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy==3.4.3 in /usr/local/lib/python3.8/dist-packages (3.4.3)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (8.1.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.4.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.0.10)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.11.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (4.64.1)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.0.8)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.21.6)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.9.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.0.8)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.23.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (21.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.10.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.0.9)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy==3.4.3) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy==3.4.3) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.4.3) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (3.0.4)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.3) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.3) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.4.3) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy==3.4.3) (2.0.1)\n"]}],"source":["!pip3 install 'spacy==3.4.3'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31369,"status":"ok","timestamp":1670274553556,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"BJDjLrN4vYJb","outputId":"34b0a028-1b32-4eee-8e4d-ae4203d9dedf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 473 kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.9.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy-transformers\n","  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 2.6 MB/s \n","\u001b[?25hCollecting transformers<4.22.0,>=3.4.0\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 55.0 MB/s \n","\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n","  Downloading spacy_alignments-0.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (1.12.1+cu113)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (2.4.5)\n","Requirement already satisfied: spacy<4.0.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (3.4.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.9.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.10.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.10.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (57.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (21.3)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (4.64.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.8)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.11.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (8.1.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy-transformers) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.4.0->spacy-transformers) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (2022.6.2)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.1)\n","Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n","Successfully installed huggingface-hub-0.11.1 spacy-alignments-0.8.6 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n"]}],"source":["!python -m spacy download en_core_web_sm\n","!pip install spacy-transformers\n","\n","## Uncomment if you want to download one of the following model\n","# !python -m spacy download en_core_web_md\n","# !python -m spacy download en_core_web_lg\n","# !python -m spacy download en_core_web_trf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3eODEDyvKJa"},"outputs":[],"source":["import spacy\n","import fnmatch\n","import os\n","import re\n","from os import path, walk\n","import shutil\n","import glob\n","import pandas as pd\n","from spacy.scorer import Scorer\n","from spacy.training import Example\n","from spacy.tokens import Doc"]},{"cell_type":"markdown","metadata":{"id":"5t5PUNu1y771"},"source":["Downloading the curated dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMfvvrEyy7jt"},"outputs":[],"source":["!wget https://raw.githubusercontent.com/MathildeAguiar/terminology_project/tree/main/data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hr1l4gtju_C7"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"CqSfN5aLPlJo"},"source":["Helpers to find files and create folders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xB74htU4sct1"},"outputs":[],"source":["def create_folder(path):\n","    \"\"\"Create a folder if it doesn't already exist\"\"\"\n","    if not os.path.isdir(path):\n","        os.makedirs(path)\n","    return\n","\n","\n","def find_files(directory, pattern='*.final'):\n","    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n","    files = []\n","    for root, dirnames, filenames in walk(directory):\n","        for filename in fnmatch.filter(filenames, pattern):\n","            files.append(path.join(root, filename))\n","    # sort the list, to avoid mismatch in the output files\n","    files = sorted(files)\n","    return files\n"]},{"cell_type":"markdown","metadata":{"id":"3bkjA0z1QWw8"},"source":["Adapt the format of the IOB tags to be supported by Spacy. Spacy expects tags in the following format: \n","```\n","B-ATTRIBUTE\n","```\n","So we convert the `B` into `B-NLP` and the `I` to `I-NLP`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1fpyTH-QHmP"},"outputs":[],"source":["def mapper(token):\n","  \"\"\"\n","  Adapts the tags into a Spacy readable format\n","  \"\"\"\n","  if token == \"B\":\n","    return \"B-NLP\"\n","  elif token == \"I\":\n","    return \"I-NLP\"\n","  else: \n","    return token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plLgYNJne8TC"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/training_data/iob \n","!mkdir /content/drive/MyDrive/Terminology_project/curated/dev_data/iob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2szcNCodVRn"},"outputs":[],"source":["def retag_files():  \n","    \"\"\" \n","    Retag the original .final files by using the Spacy tag format.\n","    Save the result into a .iob file.    \n","    \"\"\"\n","    # First process the training files\n","    directory_tg_train = \"/content/drive/MyDrive/Terminology_project/curated/training_data/\" \n","    all_training_files = find_files(directory_tg_train) \n","    for f in all_training_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_train+\"iob/\"+tmp[0].split(\".\")[0]+\".iob\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue \n","                new_file.write(new_txt)\n","            new_file.close()\n","\n","    # 2nd process the dev files\n","    directory_tg_dev = \"/content/drive/MyDrive/Terminology_project/curated/dev_data/\"  \n","    all_dev_files = find_files(directory_tg_dev)\n","    for f in all_dev_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_dev+\"iob/\"+tmp[0].split(\".\")[0]+\".iob\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue \n","                new_file.write(new_txt)\n","            new_file.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vkNp-Oh0hGw1"},"outputs":[],"source":["retag_files()"]},{"cell_type":"markdown","metadata":{"id":"wmYsiG0WbYcy"},"source":["### Convert the IOB files into *.spacy* binary files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jYraN5Rbg6C"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/training_data/iob/output \n","!mkdir /content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109994,"status":"ok","timestamp":1670064251464,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"8MWTxWr7csaL","outputId":"716578a8-0982-4355-9683-dacdc97eaecf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-1-29-46.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-1-3-28.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-1-47-59.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-2-229-270.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-2-271-306.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-3-313-343.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-3-399-433.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2009-35-4-529-558.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-1-111-127.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-1-129-149.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-1-71-109.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-2-159-201.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-2-203-227.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-2-247-277.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2010-36-3-303-339.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-657-688.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-689-698.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-699-725.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-727-752.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-753-809.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-811-842.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-843-865.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2011-37-4-867-879.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-1-1-39.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-1-113-134.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-1-41-71.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-1-73-111.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-2-223-260.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-2-261-299.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-3-479-526.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2012-38-3-527-574.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-1-121–160.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-1-195–227.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-1-23_55.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-2-229–266.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-2-267–300.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-3-511–554.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2013-39-3-555–590.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-1-121-170.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-1-171-202.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-1-57-84.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-1-85-120.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-1-9-56.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-2-269-310.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-2-349-401.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2014-40-2-403-448.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-1-1-20.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-1-119-147.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-1-21-40.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-1-41-70.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-1-71-118.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-2-185-214.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-2-215-247.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2015-41-2-249-291.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-1-121_161.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-1-91_120.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-2-245-275.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-2-277_306.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-2-307-343.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-3-391-419.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-4-637_660.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2016-42-4-661_701.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-1-125-179.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-1-181-200.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-1-71-123.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-3-465-520.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-3-521-565.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-4-683-722.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-4-723-760.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-4-761-780.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2017-43-4-781-835.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-1-17-37.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-1-39-83.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-1-85-118.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-2-285-327.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-2-329-348.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-2-349-374.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-3-403-446.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2018-44-3-447-482.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-1-1-57.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-1-137-161.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-1-163-197.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-1-59-94.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-1-95-136.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-2-199-228.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-2-229-265.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2019-45-2-267-292.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-1-1-52.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-1-53-93.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-1-95-134.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-2-249-255.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-2-257-288.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-2-289-333.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-3-515-569.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob/output/2020-46-3-571-603.spacy\u001b[0m\n"]}],"source":["## For the training set ##\n","# Uncomment the line you want in function of the model you are using \n","!python -m spacy convert -c iob -s -n 10000 -b en_core_web_sm /content/drive/MyDrive/Terminology_project/curated/training_data/iob /content/drive/MyDrive/Terminology_project/curated/training_data/iob/output\n","\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_md /curated/training_data/iob /curated/training_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_lg /curated/training_data/iob /curated/training_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /curated/training_data/iob /curated/training_data/iob/output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22431,"status":"ok","timestamp":1670064400833,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"tL3f95SZgEzL","outputId":"114c8a1f-6e73-4c0c-d5a6-df97d9527225"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2009-35-4-597-635.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2010-36-1-1-30.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2011-37-3-421-454.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2012-38-4-867-915.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2013-39-1-15–22.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2014-40-2-449-468.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2015-41-3-355-383.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2016-42-4-727-761.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2017-43-1-31-70.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2018-44-1-119-186.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2019-45-2-293-337.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output/2020-46-3-605-665.spacy\u001b[0m\n"]}],"source":["## For the dev set ##\n","# Uncomment the line you want in function of the model you are using \n","!python -m spacy convert -c iob -s -n 10000 -b en_core_web_sm /content/drive/MyDrive/Terminology_project/curated/dev_data/iob /content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output\n","\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_md /curated/dev_data/iob /curated/dev_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_lg /curated/dev_data/iob /curated/dev_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /curated/dev_data/iob /curated/dev_data/iob/output"]},{"cell_type":"markdown","metadata":{"id":"JFYi9DyTymXI"},"source":["# Training the pipeline\n","\n","First convert the base-config into a config file and then simply using the command line `spacy train`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9442,"status":"ok","timestamp":1670065954775,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"YzYaoHbjiiCv","outputId":"c7f84ebe-6648-4a80-c780-c3bd652c5ed6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}],"source":["# If the GPU is available run this cell \n","!python -m spacy init fill-config /content/drive/MyDrive/Terminology_project/base_config_CPU2.cfg config.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1670065046210,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"cjMiadJ5C3l3","outputId":"628672af-2a8f-4684-d0e7-c552e762e3eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/Terminology_project/output_clean’: File exists\n"]}],"source":["!mkdir /content/drive/MyDrive/Terminology_project/output_clean  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137208,"status":"ok","timestamp":1670066172379,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"TgpO_RW3hM_w","outputId":"ac2ec251-2c61-4a60-e2ac-dc9ec931fd76"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/Terminology_project/output_clean\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-12-03 11:14:01,089] [INFO] Set up nlp object from config\n","INFO:spacy:Set up nlp object from config\n","[2022-12-03 11:14:01,100] [INFO] Pipeline: ['tok2vec', 'tagger', 'ner']\n","INFO:spacy:Pipeline: ['tok2vec', 'tagger', 'ner']\n","[2022-12-03 11:14:01,103] [INFO] Created vocabulary\n","INFO:spacy:Created vocabulary\n","[2022-12-03 11:14:01,104] [INFO] Finished initializing nlp object\n","INFO:spacy:Finished initializing nlp object\n","[2022-12-03 11:14:02,715] [INFO] Initialized pipeline components: ['tok2vec', 'tagger', 'ner']\n","INFO:spacy:Initialized pipeline components: ['tok2vec', 'tagger', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS NER  TAG_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  -----------  --------  -------  ------  ------  ------  ------\n","  0       0          0.00         0.00     75.67   100.00    1.60    2.75    1.13    0.51\n","  2     200        182.52         0.00   7550.78   100.00   56.60   56.82   56.39    0.78\n","  4     400        290.96         0.00   3400.56   100.00   55.62   54.51   56.77    0.78\n","  6     600        349.07         0.00   2216.54   100.00   54.69   56.91   52.63    0.77\n","  8     800        411.69         0.00   1651.80   100.00   56.25   63.08   50.75    0.78\n"," 10    1000        621.56         0.00   1256.96   100.00   55.27   58.65   52.26    0.78\n"," 12    1200        493.95         0.00    845.48   100.00   54.85   54.44   55.26    0.77\n"," 14    1400        609.56         0.00    729.20   100.00   54.36   59.03   50.38    0.77\n"," 16    1600        572.31         0.00    711.53   100.00   53.23   55.51   51.13    0.77\n"," 18    1800        563.58         0.00    604.32   100.00   54.62   58.62   51.13    0.77\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/Terminology_project/output_clean/model-last\n"]}],"source":["!python -m spacy train /content/config.cfg --output /content/drive/MyDrive/Terminology_project/output_clean --paths.train /content/drive/MyDrive/Terminology_project/curated/training_data/iob/output --paths.dev /content/drive/MyDrive/Terminology_project/curated/dev_data/iob/output"]},{"cell_type":"markdown","metadata":{"id":"rWFTFgALm_vu"},"source":["You should obtain 2 models: `model-best` and `model-base`. To test the trained Pipeline it's better to use `model-best`. "]},{"cell_type":"markdown","metadata":{"id":"eegY9I5iypna"},"source":["# Testing on the test dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rNkoBFe8t8e0"},"source":["### Preprocessinf the test files "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsXqdVbMwj0r"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/test_data/conv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zq_gYbK3uCcO"},"outputs":[],"source":["def retag_test_files():\n","    \"\"\" \n","    Retag the original .final files by using the Spacy tag format.\n","    Save the result into a .iob file.    \n","    \"\"\"\n","    # First process the test files\n","    directory_tg_test = \"/content/drive/MyDrive/Terminology_project/curated/test_data/\"  \n","    all_test_files = glob.glob(directory_tg_test + \"/*.final\")\n","    for f in all_test_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_test+\"conv/\"+tmp[0].split(\".\")[0]+\".final\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue \n","                new_file.write(new_txt)\n","            new_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6DR4TwhuY1I"},"outputs":[],"source":["retag_test_files()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuDHRMmcodKH"},"outputs":[],"source":["path = r'/content/drive/MyDrive/Terminology_project/curated/test_data/conv'\n","all_files = glob.glob(path + \"/*.final\")\n","\n","l = []\n","cols = ['Token', 'Tag']\n","\n","for filename in all_files:\n","    df = pd.read_csv(filename, names = cols,on_bad_lines='skip', sep='\\s+', engine='python')\n","    l.append(df)\n","\n","# Our tokens from test set are stored in a Dataframe\n","test_df = pd.concat(l, axis=0, ignore_index=True)\n","\n","# drop nan values\n","test_df = test_df.dropna()\n","test_df['Token'].fillna('', inplace=True)\n"]},{"cell_type":"markdown","metadata":{"id":"VVt0mxKPuGT5"},"source":["## Using Scorer to test on the test sentences "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":625,"status":"ok","timestamp":1670274805241,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"v4djHJo-9VCb","outputId":"52865f22-3447-41a7-c17b-25ce4284c2b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2772\n","2772\n"]}],"source":["test_df.head()\n","test_df.iloc[88]\n","print(len(test_df['Token']))\n","print(len(test_df['Tag']))"]},{"cell_type":"markdown","metadata":{"id":"3sjKI1PKA4DV"},"source":["### Using the command line"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39956,"status":"ok","timestamp":1670277753274,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"BLm30wgjPYgD","outputId":"d521f1ce-ebf3-4486-a80b-8ac15601b9ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2009-35-4-559-595.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2009-35-4-559-595.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2010-36-1-31-69.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2010-36-1-31-69.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2011-37-3-455-488.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2011-37-3-455-488.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2012-38-4-827-865.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2012-38-4-827-865.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2013-39-4-999–1023.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2013-39-4-999–1023.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2014-40-2-469-510.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2014-40-2-469-510.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2015-41-2-293-336.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2015-41-2-293-336.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2016-42-3-491-525.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2016-42-3-491-525.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2017-43-1-1-30.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2017-43-1-1-30.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2018-44-3-525-546.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2018-44-3-525-546.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2019-45-2-339-379_.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2019-45-2-339-379_.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2020-46-4-745-762.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2020-46-4-745-762.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2021-47-1-43-68.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_sm'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/conv/output/2021-47-1-43-68.spacy\u001b[0m\n"]}],"source":["!python -m spacy convert -c iob -s -n 10000 -b en_core_web_sm /content/drive/MyDrive/Terminology_project/curated/test_data/conv /content/drive/MyDrive/Terminology_project/curated/test_data/conv/output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7878,"status":"ok","timestamp":1670277794099,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"idRE4oYJm9xE","outputId":"a2ba5adf-f557-47f2-b730-3a0b1b77ee1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     -     \n","TAG     100.00\n","NER P   57.05 \n","NER R   53.61 \n","NER F   55.28 \n","SPEED   24486 \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P       R       F\n","NLP   57.05   53.61   55.28\n","\n"]}],"source":["!python -m spacy evaluate /content/drive/MyDrive/Terminology_project/output_clean/model-best /content/drive/MyDrive/Terminology_project/curated/test_data/conv/output"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOf5R6erjaUeo9fl6PdK0+Y","mount_file_id":"1PLrs33iGiWFUxds7X8mTBx6RAGrLMiCD","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
