{"cells":[{"cell_type":"markdown","metadata":{"id":"WwIPrtcWupfb"},"source":["# Terminology project \n","\n","## **Spacy trainable pipe**\n","\n","### AGUIAR Mathilde NIAOURI Dimitra\n","\n","#### M2 NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DLW1ZVblu5ZH"},"source":["# Goal and tools "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32354,"status":"ok","timestamp":1670695957571,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"PlYl49hV0NLR","outputId":"d67378b8-6e78-4af8-db3a-3d85036fa2d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UWa0GcjdvK9E"},"source":["#### Imports and packages "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3386,"status":"ok","timestamp":1670695960946,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"nBDuuHj5Ip6Y","outputId":"594c16f5-6b1e-4e16-e3b3-c7775e7fc815"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy==3.4.3 in /usr/local/lib/python3.8/dist-packages (3.4.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.0.7)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.10.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.11.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.4.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (4.64.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.0.10)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (21.3)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.7.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.0.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (57.4.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (3.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.0.3)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (8.1.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (1.10.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3) (0.10.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy==3.4.3) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy==3.4.3) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.4.3) (4.4.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.3) (1.24.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.3) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.3) (0.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.4.3) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy==3.4.3) (2.0.1)\n"]}],"source":["!pip3 install 'spacy==3.4.3'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209426,"status":"ok","timestamp":1670696170365,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"BJDjLrN4vYJb","outputId":"a1f386c1-53e2-4fac-cc68-9247f3a1b823"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy-transformers\n","  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (1.13.0+cu116)\n","Collecting spacy-alignments<1.0.0,>=0.7.2\n","  Downloading spacy_alignments-0.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (3.4.3)\n","Collecting transformers<4.22.0,>=3.4.0\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers) (2.4.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.9)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.10.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.11.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.10.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.23.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (4.64.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.10)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.10.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (57.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.7)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.21.6)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (8.1.5)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy-transformers) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.4.0->spacy-transformers) (4.4.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.10)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.0.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (6.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.1)\n","Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n","Successfully installed huggingface-hub-0.11.1 spacy-alignments-0.8.6 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-trf==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.4.1/en_core_web_trf-3.4.1-py3-none-any.whl (460.3 MB)\n","\u001b[K     |████████████████████████████████| 460.3 MB 28 kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.1 in /usr/local/lib/python3.8/dist-packages (from en-core-web-trf==3.4.1) (3.4.3)\n","Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from en-core-web-trf==3.4.1) (1.1.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.11.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (57.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.10.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.7.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (21.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.23.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.10.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.0.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.10)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.21.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.4.5)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.0.3)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (8.1.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2022.9.24)\n","Requirement already satisfied: transformers<4.22.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (4.21.3)\n","Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (0.8.6)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (1.13.0+cu116)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.0.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (0.11.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (6.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.1)\n","Installing collected packages: en-core-web-trf\n","Successfully installed en-core-web-trf-3.4.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_trf')\n"]}],"source":["#!python -m spacy download en_core_web_sm\n","!pip install spacy-transformers\n","\n","## Uncomment if you want to download one of the following model\n","# !python -m spacy download en_core_web_md\n","# !python -m spacy download en_core_web_lg\n","!python -m spacy download en_core_web_trf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3eODEDyvKJa"},"outputs":[],"source":["import spacy\n","import fnmatch\n","import os\n","import re\n","from os import path, walk\n","import shutil\n","import glob\n","import pandas as pd\n","from spacy.scorer import Scorer\n","from spacy.training import Example\n","from spacy.tokens import Doc"]},{"cell_type":"markdown","metadata":{"id":"5t5PUNu1y771"},"source":["Downloading the curated dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMfvvrEyy7jt"},"outputs":[],"source":["!wget https://raw.githubusercontent.com/MathildeAguiar/terminology_project/tree/main/data"]},{"cell_type":"markdown","metadata":{"id":"hr1l4gtju_C7"},"source":["# Data Preprocessing\n","\n","\n","blah blah blah TODO"]},{"cell_type":"markdown","metadata":{"id":"CqSfN5aLPlJo"},"source":["Helpers to find files and create folders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xB74htU4sct1"},"outputs":[],"source":["def create_folder(path):\n","    \"\"\"Create a folder if it doesn't already exist\"\"\"\n","    if not os.path.isdir(path):\n","        os.makedirs(path)\n","    return\n","\n","\n","def find_files(directory, pattern='*.final'):\n","    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n","    files = []\n","    for root, dirnames, filenames in walk(directory):\n","        for filename in fnmatch.filter(filenames, pattern):\n","            files.append(path.join(root, filename))\n","    # sort the list, to avoid mismatch in the output files\n","    files = sorted(files)\n","    return files\n"]},{"cell_type":"markdown","metadata":{"id":"3bkjA0z1QWw8"},"source":["Adapt the format of the IOB tags to be supported by Spacy. Spacy expects tags in the following format: \n","```\n","B-ATTRIBUTE\n","```\n","So we convert the `B` into `B-NLP` and the `I` to `I-NLP`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1fpyTH-QHmP"},"outputs":[],"source":["def mapper(token):\n","  \"\"\"\n","  Adapts the tags into a Spacy readable format\n","  \"\"\"\n","  if token == \"B\":\n","    return \"B-NLP\"\n","  elif token == \"I\":\n","    return \"I-NLP\"\n","  else: \n","    return token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plLgYNJne8TC"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf \n","!mkdir /content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2szcNCodVRn"},"outputs":[],"source":["def retag_files():  \n","    \"\"\" \n","    Retag the original .final files by using the Spacy tag format.\n","    Save the result into a .iob file.    \n","    \"\"\"\n","    # First process the training files\n","    directory_tg_train = \"/content/drive/MyDrive/Terminology_project/curated/training_data/\"  \n","    all_training_files = find_files(directory_tg_train) \n","    for f in all_training_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_train+\"iob_trf/\"+tmp[0].split(\".\")[0]+\".iob\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue  \n","                new_file.write(new_txt)\n","            new_file.close()\n","\n","    # 2nd process the dev files\n","    directory_tg_dev = \"/content/drive/MyDrive/Terminology_project/curated/dev_data/\" \n","    all_dev_files = find_files(directory_tg_dev)\n","    for f in all_dev_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_dev+\"iob_trf/\"+tmp[0].split(\".\")[0]+\".iob\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue  \n","                new_file.write(new_txt)\n","            new_file.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vkNp-Oh0hGw1"},"outputs":[],"source":["retag_files()"]},{"cell_type":"markdown","metadata":{"id":"wmYsiG0WbYcy"},"source":["### Convert the IOB files into *.spacy* binary files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jYraN5Rbg6C"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output \n","!mkdir /content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":696392,"status":"ok","timestamp":1670678729690,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"8MWTxWr7csaL","outputId":"174cd928-c0a2-424f-d20a-958645b84509"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-1-29-46.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-1-3-28.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-1-47-59.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-2-229-270.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-2-271-306.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-3-313-343.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-3-399-433.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2009-35-4-529-558.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-1-111-127.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-1-129-149.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-1-71-109.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-2-159-201.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-2-203-227.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-2-247-277.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2010-36-3-303-339.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-657-688.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-689-698.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-699-725.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-727-752.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-753-809.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-811-842.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-843-865.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2011-37-4-867-879.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-1-1-39.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-1-113-134.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-1-41-71.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-1-73-111.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-2-223-260.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-2-261-299.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-3-479-526.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2012-38-3-527-574.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-1-121–160.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-1-195–227.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-1-23_55.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-2-229–266.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-2-267–300.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-3-511–554.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2013-39-3-555–590.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-1-121-170.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-1-171-202.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-1-57-84.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-1-85-120.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-1-9-56.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-2-269-310.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-2-349-401.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2014-40-2-403-448.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-1-1-20.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-1-119-147.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-1-21-40.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-1-41-70.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-1-71-118.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-2-185-214.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-2-215-247.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2015-41-2-249-291.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-1-121_161.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-1-91_120.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-2-245-275.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-2-277_306.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-2-307-343.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-3-391-419.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-4-637_660.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2016-42-4-661_701.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-1-125-179.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-1-181-200.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-1-71-123.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-3-465-520.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-3-521-565.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-4-683-722.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-4-723-760.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-4-761-780.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2017-43-4-781-835.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-1-17-37.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-1-39-83.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-1-85-118.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-2-285-327.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-2-329-348.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-2-349-374.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-3-403-446.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2018-44-3-447-482.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-1-1-57.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-1-137-161.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-1-163-197.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-1-59-94.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-1-95-136.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-2-199-228.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-2-229-265.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2019-45-2-267-292.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-1-1-52.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-1-53-93.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-1-95-134.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-2-249-255.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-2-257-288.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-2-289-333.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-3-515-569.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output/2020-46-3-571-603.spacy\u001b[0m\n"]}],"source":["## For the training set ##\n","# Uncomment the line you want in function of the model you are using \n","!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf /content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output\n","\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_md /curated/training_data/iob /curated/training_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_lg /curated/training_data/iob /curated/training_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /curated/training_data/iob /curated/training_data/iob/output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100166,"status":"ok","timestamp":1670678829849,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"tL3f95SZgEzL","outputId":"b0ecb494-b164-4560-9973-d5d79d414693"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2009-35-4-597-635.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2010-36-1-1-30.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2011-37-3-421-454.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2012-38-4-867-915.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2013-39-1-15–22.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2014-40-2-449-468.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2015-41-3-355-383.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2016-42-4-727-761.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2017-43-1-31-70.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2018-44-1-119-186.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2019-45-2-293-337.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output/2020-46-3-605-665.spacy\u001b[0m\n"]}],"source":["## For the dev set ##\n","# Uncomment the line you want in function of the model you are using \n","!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf /content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output\n","\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_md /curated/dev_data/iob /curated/dev_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_lg /curated/dev_data/iob /curated/dev_data/iob/output\n","#!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /curated/dev_data/iob /curated/dev_data/iob/output"]},{"cell_type":"markdown","metadata":{"id":"JFYi9DyTymXI"},"source":["# Training the pipeline\n","\n","First convert the base-config into a config file and then simply using the command line `spacy train`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11107,"status":"ok","timestamp":1670696188793,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"YzYaoHbjiiCv","outputId":"7db8c66c-b99e-44ad-9d54-795d91a99469"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}],"source":["# If the GPU is available run this cell \n","!python -m spacy init fill-config /content/drive/MyDrive/Terminology_project/base_config_ner_gpu.cfg config.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjMiadJ5C3l3"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/output_clean_trf  "]},{"cell_type":"markdown","metadata":{"id":"VTNV3n-RRcHB"},"source":["Test if there is a GPU available"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1670680735343,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"b-zt8VGpRWCi","outputId":"32399aff-aaae-411f-9ea9-c4a78d043bb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["gpu = spacy.prefer_gpu()\n","print(gpu)"]},{"cell_type":"markdown","metadata":{"id":"qrtKhs22RfTE"},"source":["If it returns False please run this command and re run the previous cell."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3611362,"status":"ok","timestamp":1670708531923,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"TgpO_RW3hM_w","outputId":"dc1e316b-abbc-4a22-882c-42020752677c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/Terminology_project/output_clean_trf\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-12-10 20:42:11,835] [INFO] Set up nlp object from config\n","INFO:spacy:Set up nlp object from config\n","[2022-12-10 20:42:11,851] [INFO] Pipeline: ['transformer', 'ner']\n","INFO:spacy:Pipeline: ['transformer', 'ner']\n","[2022-12-10 20:42:11,855] [INFO] Created vocabulary\n","INFO:spacy:Created vocabulary\n","[2022-12-10 20:42:11,856] [INFO] Finished initializing nlp object\n","INFO:spacy:Finished initializing nlp object\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-12-10 20:42:45,761] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3890.06    274.50    0.00    0.00    0.00    0.00\n"," 16     200      373118.14  69065.81   62.72   58.44   67.67    0.63\n"," 33     400        6495.70   9551.12   65.85   72.20   60.53    0.66\n"," 50     600         956.73   2019.70   68.57   65.31   72.18    0.69\n"," 66     800         459.61   1467.33   65.40   66.15   64.66    0.65\n"," 83    1000         442.02   1339.03   64.45   67.07   62.03    0.64\n","100    1200         320.88   1214.89   68.15   67.15   69.17    0.68\n","116    1400         339.07   1246.98   64.31   63.60   65.04    0.64\n","133    1600         315.25   1076.57   68.40   67.65   69.17    0.68\n","150    1800         286.07   1072.13   67.61   63.88   71.80    0.68\n","166    2000         150.67    923.64   67.54   67.42   67.67    0.68\n","183    2200         189.17    877.07   66.42   64.87   68.05    0.66\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/Terminology_project/output_clean_trf/model-last\n"]}],"source":["!python -m spacy train --gpu-id 0 /content/config.cfg --output /content/drive/MyDrive/Terminology_project/output_clean_trf --paths.train /content/drive/MyDrive/Terminology_project/curated/training_data/iob_trf/output --paths.dev /content/drive/MyDrive/Terminology_project/curated/dev_data/iob_trf/output"]},{"cell_type":"markdown","metadata":{"id":"rWFTFgALm_vu"},"source":["You should obtain 2 models: `model-best` and `model-base`. To test the trained Pipeline it's better to use `model-best`. "]},{"cell_type":"markdown","metadata":{"id":"eegY9I5iypna"},"source":["# Testing on the test dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rNkoBFe8t8e0"},"source":["### Preprocessinf the test files "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsXqdVbMwj0r"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zq_gYbK3uCcO"},"outputs":[],"source":["def retag_test_files():\n","    \"\"\" \n","    Retag the original .final files by using the Spacy tag format.\n","    Save the result into a .iob file.    \n","    \"\"\"\n","    # First process the test files\n","    directory_tg_test = \"/content/drive/MyDrive/Terminology_project/curated/test_data/\"\n","    all_test_files = glob.glob(directory_tg_test + \"/*.final\")\n","    for f in all_test_files:\n","        with open(f, mode='r', encoding='utf-8') as myfile:\n","            lines = myfile.readlines()\n","            tmp = re.findall('\\d{4}-\\S*', f)\n","            iob_file_name = directory_tg_test+\"iob_trf/\"+tmp[0].split(\".\")[0]+\".iob\"\n","            new_file = open(iob_file_name, \"a\")\n","            for l in lines:\n","              if not l.isspace():\n","                words = l.split()\n","                new_array = list(map(mapper, words))\n","                if len(new_array)>1:\n","                    new_txt = new_array[0]+\"\\t\"+new_array[1]+\"\\n\"\n","                elif len(new_array)>0:\n","                    new_txt = new_array[0]+\"\\n\"\n","                else: continue  \n","                new_file.write(new_txt)\n","            new_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6DR4TwhuY1I"},"outputs":[],"source":["retag_test_files()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuDHRMmcodKH"},"outputs":[],"source":["path = r'/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf'\n","all_files = glob.glob(path + \"/*.iob\")\n","\n","l = []\n","cols = ['Token', 'Tag']\n","\n","for filename in all_files:\n","    df = pd.read_csv(filename, names = cols,on_bad_lines='skip', sep='\\s+', engine='python')\n","    l.append(df)\n","\n","# Our tokens from test set are stored in a Dataframe\n","test_df = pd.concat(l, axis=0, ignore_index=True)\n","\n","# drop nan values\n","test_df = test_df.dropna()\n","test_df['Token'].fillna('', inplace=True)\n"]},{"cell_type":"markdown","metadata":{"id":"VVt0mxKPuGT5"},"source":["## Using Scorer to test on the test sentences "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670709049923,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"v4djHJo-9VCb","outputId":"2d2b4e96-682e-4e57-8dc7-1918d9c68039"},"outputs":[{"name":"stdout","output_type":"stream","text":["2772\n","2772\n"]}],"source":["test_df.head()\n","test_df.iloc[88]\n","print(len(test_df['Token']))\n","print(len(test_df['Tag']))"]},{"cell_type":"markdown","metadata":{"id":"3sjKI1PKA4DV"},"source":["### Using the command line"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ri2zcB4P_t3w"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104868,"status":"ok","timestamp":1670709617729,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"BLm30wgjPYgD","outputId":"4d370aee-1e8a-4471-cb4b-107b630f772d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2009-35-4-559-595.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2010-36-1-31-69.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2011-37-3-455-488.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2012-38-4-827-865.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2013-39-4-999–1023.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2014-40-2-469-510.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2015-41-2-293-336.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2016-42-3-491-525.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2017-43-1-1-30.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2018-44-3-525-546.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2019-45-2-339-379_.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2020-46-4-745-762.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10000 sentences into a document.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with parser from model 'en_core_web_trf'.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output/2021-47-1-43-68.spacy\u001b[0m\n"]}],"source":["!python -m spacy convert -c iob -s -n 10000 -b en_core_web_trf /content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf /content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19870,"status":"ok","timestamp":1670709656738,"user":{"displayName":"mathilde aguiar","userId":"08567753690464362016"},"user_tz":-60},"id":"idRE4oYJm9xE","outputId":"f9f15c3d-a804-411b-c2a4-a7f0e89caf8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     -    \n","NER P   63.40\n","NER R   66.27\n","NER F   64.80\n","SPEED   2116 \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P       R       F\n","NLP   63.40   66.27   64.80\n","\n"]}],"source":["!python -m spacy evaluate --gpu-id 0 /content/drive/MyDrive/Terminology_project/output_clean_trf/model-best /content/drive/MyDrive/Terminology_project/curated/test_data/iob_trf/output"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMGYwmp/3NiZkZIvBCMp0UV","mount_file_id":"1WhZPCoJZIJi4Lot8G8ZBVXgNC9x_ayHO","provenance":[{"file_id":"1PLrs33iGiWFUxds7X8mTBx6RAGrLMiCD","timestamp":1670677622351}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
